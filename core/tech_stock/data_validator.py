"""
ç§‘æŠ€è‚¡æ•°æ®éªŒè¯å™¨æ¨¡å—

æä¾›ç§‘æŠ€è‚¡æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å’ŒéªŒè¯åŠŸèƒ½ï¼Œç¡®ä¿å›æµ‹å‰æ•°æ®çš„å¯ç”¨æ€§ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ•°æ®æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
2. æ•°æ®æ—¶é—´èŒƒå›´éªŒè¯
3. æ•°æ®æ ¼å¼å®Œæ•´æ€§éªŒè¯
4. ç¼ºå¤±æ•°æ®æŠ¥å‘Šç”Ÿæˆ
5. å‹å¥½çš„é”™è¯¯ä¿¡æ¯ç³»ç»Ÿ

Requirements: 1.1, 1.2, 4.1, 4.2, 5.1
"""

from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime, date
import pandas as pd
import os
import logging

from config.tech_stock_pool import get_tech_stock_pool
from core.data_feed import DataFeed

logger = logging.getLogger(__name__)


# ========== æ ‡å‡†åŒ–é”™è¯¯ä¿¡æ¯æ¨¡æ¿ (Task 5.1) ==========
class ErrorMessages:
    """
    æ ‡å‡†åŒ–é”™è¯¯ä¿¡æ¯æ¨¡æ¿
    
    æä¾›ç»Ÿä¸€çš„é”™è¯¯ä¿¡æ¯æ ¼å¼ï¼Œæ”¯æŒä¸­æ–‡æ˜¾ç¤ºã€‚
    
    Requirements: 1.2, 1.3, 5.1
    """
    
    # æ•°æ®ç¼ºå¤±ç›¸å…³
    MISSING_DATA_FILE = "æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨"
    MISSING_DATA_FILE_DETAIL = "è‚¡ç¥¨ {code}({name}) çš„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ä¸‹è½½æ•°æ®"
    
    # æ•°æ®ä¸è¶³ç›¸å…³
    INSUFFICIENT_DATA = "æ•°æ®æ—¶é—´èŒƒå›´ä¸è¶³"
    INSUFFICIENT_DATA_DETAIL = "è‚¡ç¥¨ {code}({name}) çš„æ•°æ®èŒƒå›´ ({first_date} ~ {last_date}) ä¸æ»¡è¶³è¦æ±‚ ({required_start} ~ {required_end})"
    
    # æ•°æ®æŸåç›¸å…³
    CORRUPTED_DATA = "æ•°æ®æ–‡ä»¶æŸå"
    CORRUPTED_DATA_DETAIL = "è‚¡ç¥¨ {code}({name}) çš„æ•°æ®æ–‡ä»¶æŸå: {error}"
    
    # æ•°æ®æ ¼å¼ç›¸å…³
    MISSING_COLUMNS = "æ•°æ®æ ¼å¼é”™è¯¯"
    MISSING_COLUMNS_DETAIL = "è‚¡ç¥¨ {code}({name}) çš„æ•°æ®ç¼ºå°‘å¿…éœ€åˆ—: {columns}"
    
    EMPTY_DATA = "æ•°æ®æ–‡ä»¶ä¸ºç©º"
    EMPTY_DATA_DETAIL = "è‚¡ç¥¨ {code}({name}) çš„æ•°æ®æ–‡ä»¶ä¸ºç©º"
    
    # ä¸‹è½½ç›¸å…³
    DOWNLOAD_FAILED = "æ•°æ®ä¸‹è½½å¤±è´¥"
    DOWNLOAD_FAILED_DETAIL = "è‚¡ç¥¨ {code}({name}) ä¸‹è½½å¤±è´¥: {error}"
    
    NETWORK_ERROR = "ç½‘ç»œè¿æ¥é”™è¯¯"
    NETWORK_ERROR_DETAIL = "æ— æ³•è¿æ¥åˆ°æ•°æ®æºï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
    
    # è§£å†³æ–¹æ¡ˆæç¤º
    SOLUTION_DOWNLOAD = "ç‚¹å‡»'ä¸‹è½½ç§‘æŠ€è‚¡æ•°æ®'æŒ‰é’®è‡ªåŠ¨è·å–æ‰€éœ€æ•°æ®"
    SOLUTION_REDOWNLOAD = "åˆ é™¤æŸåçš„æ•°æ®æ–‡ä»¶åé‡æ–°ä¸‹è½½"
    SOLUTION_DATA_MANAGER = "å‰å¾€'æ•°æ®ç®¡ç†'é¡µé¢çš„'ç§‘æŠ€è‚¡æ•°æ®ä¸“åŒº'ç®¡ç†æ•°æ®"
    SOLUTION_CHECK_NETWORK = "è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•"
    SOLUTION_RETRY = "ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ"
    
    @classmethod
    def format_missing_data(cls, code: str, name: str) -> str:
        """æ ¼å¼åŒ–æ•°æ®ç¼ºå¤±é”™è¯¯ä¿¡æ¯"""
        return cls.MISSING_DATA_FILE_DETAIL.format(code=code, name=name)
    
    @classmethod
    def format_insufficient_data(
        cls, code: str, name: str, 
        first_date: str, last_date: str,
        required_start: str, required_end: str
    ) -> str:
        """æ ¼å¼åŒ–æ•°æ®ä¸è¶³é”™è¯¯ä¿¡æ¯"""
        return cls.INSUFFICIENT_DATA_DETAIL.format(
            code=code, name=name,
            first_date=first_date, last_date=last_date,
            required_start=required_start, required_end=required_end
        )
    
    @classmethod
    def format_corrupted_data(cls, code: str, name: str, error: str) -> str:
        """æ ¼å¼åŒ–æ•°æ®æŸåé”™è¯¯ä¿¡æ¯"""
        return cls.CORRUPTED_DATA_DETAIL.format(code=code, name=name, error=error)
    
    @classmethod
    def format_missing_columns(cls, code: str, name: str, columns: List[str]) -> str:
        """æ ¼å¼åŒ–ç¼ºå°‘åˆ—é”™è¯¯ä¿¡æ¯"""
        return cls.MISSING_COLUMNS_DETAIL.format(
            code=code, name=name, columns=', '.join(columns)
        )
    
    @classmethod
    def get_solution_hints(cls, has_missing: bool, has_insufficient: bool, has_corrupted: bool) -> List[str]:
        """è·å–è§£å†³æ–¹æ¡ˆæç¤ºåˆ—è¡¨"""
        hints = []
        
        if has_missing or has_insufficient:
            hints.append(cls.SOLUTION_DOWNLOAD)
        
        if has_corrupted:
            hints.append(cls.SOLUTION_REDOWNLOAD)
        
        hints.append(cls.SOLUTION_DATA_MANAGER)
        
        return hints


@dataclass
class DataValidationResult:
    """æ•°æ®éªŒè¯ç»“æœ"""
    is_valid: bool
    missing_files: List[str]
    insufficient_data: List[Dict[str, str]]
    corrupted_files: List[str]
    total_stocks: int
    valid_stocks: int
    error_message: Optional[str] = None
    solution_hint: Optional[str] = None


@dataclass
class StockDataStatus:
    """å•åªè‚¡ç¥¨æ•°æ®çŠ¶æ€"""
    code: str
    name: str
    has_file: bool
    file_path: Optional[str]
    first_date: Optional[str]
    last_date: Optional[str]
    record_count: int
    is_sufficient: bool
    error_message: Optional[str] = None


class TechDataValidator:
    """
    ç§‘æŠ€è‚¡æ•°æ®éªŒè¯å™¨
    
    è´Ÿè´£æ£€æŸ¥ç§‘æŠ€è‚¡æ± ä¸­æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ®å®Œæ•´æ€§ï¼ŒåŒ…æ‹¬ï¼š
    - æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    - æ•°æ®æ—¶é—´èŒƒå›´æ˜¯å¦è¶³å¤Ÿ
    - æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
    - ç”Ÿæˆè¯¦ç»†çš„éªŒè¯æŠ¥å‘Š
    
    Requirements: 1.1, 1.2, 4.1, 4.2
    """
    
    def __init__(self, data_feed: Optional[DataFeed] = None):
        """
        åˆå§‹åŒ–æ•°æ®éªŒè¯å™¨
        
        Args:
            data_feed: æ•°æ®è·å–æ¨¡å—å®ä¾‹
        """
        self.data_feed = data_feed
        self.tech_stock_pool = get_tech_stock_pool()
    
    def validate_tech_stock_data(
        self, 
        stock_codes: Optional[List[str]] = None,
        required_start_date: Optional[str] = None,
        required_end_date: Optional[str] = None
    ) -> DataValidationResult:
        """
        éªŒè¯ç§‘æŠ€è‚¡æ•°æ®å®Œæ•´æ€§
        
        Args:
            stock_codes: è¦éªŒè¯çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ŒNoneæ—¶éªŒè¯æ•´ä¸ªç§‘æŠ€è‚¡æ± 
            required_start_date: è¦æ±‚çš„æ•°æ®å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            required_end_date: è¦æ±‚çš„æ•°æ®ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        
        Returns:
            æ•°æ®éªŒè¯ç»“æœ
            
        Requirements: 1.1, 4.1
        """
        # ä½¿ç”¨ç§‘æŠ€è‚¡æ± ä¸­çš„æ‰€æœ‰è‚¡ç¥¨ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
        if stock_codes is None:
            stock_codes = self.tech_stock_pool.get_all_codes()
        
        logger.info(f"å¼€å§‹éªŒè¯ç§‘æŠ€è‚¡æ•°æ®: {len(stock_codes)} åªè‚¡ç¥¨")
        
        missing_files = []
        insufficient_data = []
        corrupted_files = []
        valid_count = 0
        
        for code in stock_codes:
            try:
                status = self.check_single_stock_data(
                    code, 
                    required_start_date, 
                    required_end_date
                )
                
                if not status.has_file:
                    missing_files.append(code)
                elif status.error_message:
                    corrupted_files.append(code)
                elif not status.is_sufficient:
                    stock_name = self.tech_stock_pool.get_stock_name(code)
                    insufficient_data.append({
                        "code": code,
                        "name": stock_name,
                        "first_date": status.first_date or "N/A",
                        "last_date": status.last_date or "N/A",
                        "required_start": required_start_date or "N/A",
                        "required_end": required_end_date or "N/A"
                    })
                else:
                    valid_count += 1
                    
            except Exception as e:
                logger.error(f"éªŒè¯è‚¡ç¥¨ {code} æ•°æ®æ—¶å‡ºé”™: {e}")
                corrupted_files.append(code)
        
        # åˆ¤æ–­æ•´ä½“éªŒè¯ç»“æœ
        is_valid = (len(missing_files) == 0 and 
                   len(insufficient_data) == 0 and 
                   len(corrupted_files) == 0)
        
        # ç”Ÿæˆé”™è¯¯ä¿¡æ¯å’Œè§£å†³æ–¹æ¡ˆ
        error_message, solution_hint = self._generate_error_message(
            missing_files, insufficient_data, corrupted_files
        )
        
        result = DataValidationResult(
            is_valid=is_valid,
            missing_files=missing_files,
            insufficient_data=insufficient_data,
            corrupted_files=corrupted_files,
            total_stocks=len(stock_codes),
            valid_stocks=valid_count,
            error_message=error_message,
            solution_hint=solution_hint
        )
        
        logger.info(f"æ•°æ®éªŒè¯å®Œæˆ: {valid_count}/{len(stock_codes)} åªè‚¡ç¥¨æ•°æ®æœ‰æ•ˆ")
        return result
    
    def check_single_stock_data(
        self,
        code: str,
        required_start_date: Optional[str] = None,
        required_end_date: Optional[str] = None
    ) -> StockDataStatus:
        """
        æ£€æŸ¥å•åªè‚¡ç¥¨çš„æ•°æ®çŠ¶æ€
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            required_start_date: è¦æ±‚çš„æ•°æ®å¼€å§‹æ—¥æœŸ
            required_end_date: è¦æ±‚çš„æ•°æ®ç»“æŸæ—¥æœŸ
        
        Returns:
            è‚¡ç¥¨æ•°æ®çŠ¶æ€
            
        Requirements: 1.1, 4.2
        """
        stock_name = self.tech_stock_pool.get_stock_name(code)
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not self.data_feed:
            return StockDataStatus(
                code=code,
                name=stock_name,
                has_file=False,
                file_path=None,
                first_date=None,
                last_date=None,
                record_count=0,
                is_sufficient=False,
                error_message="DataFeed æœªåˆå§‹åŒ–"
            )
        
        file_path = os.path.join(self.data_feed.processed_path, f"{code}.csv")
        
        if not os.path.exists(file_path):
            return StockDataStatus(
                code=code,
                name=stock_name,
                has_file=False,
                file_path=file_path,
                first_date=None,
                last_date=None,
                record_count=0,
                is_sufficient=False
            )
        
        # å°è¯•åŠ è½½å’ŒéªŒè¯æ•°æ®
        try:
            df = pd.read_csv(file_path)
            
            # æ£€æŸ¥å¿…éœ€çš„åˆ—
            required_columns = ['date', 'open', 'high', 'low', 'close', 'volume']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                return StockDataStatus(
                    code=code,
                    name=stock_name,
                    has_file=True,
                    file_path=file_path,
                    first_date=None,
                    last_date=None,
                    record_count=len(df),
                    is_sufficient=False,
                    error_message=f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}"
                )
            
            if df.empty:
                return StockDataStatus(
                    code=code,
                    name=stock_name,
                    has_file=True,
                    file_path=file_path,
                    first_date=None,
                    last_date=None,
                    record_count=0,
                    is_sufficient=False,
                    error_message="æ•°æ®æ–‡ä»¶ä¸ºç©º"
                )
            
            # è·å–æ•°æ®æ—¶é—´èŒƒå›´
            df['date'] = pd.to_datetime(df['date'])
            first_date = df['date'].min().strftime('%Y-%m-%d')
            last_date = df['date'].max().strftime('%Y-%m-%d')
            
            # æ£€æŸ¥æ—¶é—´èŒƒå›´æ˜¯å¦è¶³å¤Ÿ
            is_sufficient = self.check_data_time_range(
                first_date, last_date, required_start_date, required_end_date
            )
            
            return StockDataStatus(
                code=code,
                name=stock_name,
                has_file=True,
                file_path=file_path,
                first_date=first_date,
                last_date=last_date,
                record_count=len(df),
                is_sufficient=is_sufficient
            )
            
        except Exception as e:
            return StockDataStatus(
                code=code,
                name=stock_name,
                has_file=True,
                file_path=file_path,
                first_date=None,
                last_date=None,
                record_count=0,
                is_sufficient=False,
                error_message=f"æ•°æ®æ–‡ä»¶æŸå: {str(e)}"
            )
    
    def check_data_time_range(
        self,
        data_start: str,
        data_end: str,
        required_start: Optional[str] = None,
        required_end: Optional[str] = None
    ) -> bool:
        """
        æ£€æŸ¥æ•°æ®æ—¶é—´èŒƒå›´æ˜¯å¦è¶³å¤Ÿ
        
        Args:
            data_start: æ•°æ®å¼€å§‹æ—¥æœŸ
            data_end: æ•°æ®ç»“æŸæ—¥æœŸ
            required_start: è¦æ±‚çš„å¼€å§‹æ—¥æœŸ
            required_end: è¦æ±‚çš„ç»“æŸæ—¥æœŸ
        
        Returns:
            æ—¶é—´èŒƒå›´æ˜¯å¦è¶³å¤Ÿ
            
        Requirements: 4.2
        """
        try:
            data_start_dt = datetime.strptime(data_start, '%Y-%m-%d')
            data_end_dt = datetime.strptime(data_end, '%Y-%m-%d')
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè¦æ±‚ï¼Œåˆ™è®¤ä¸ºè¶³å¤Ÿ
            if not required_start and not required_end:
                return True
            
            if required_start:
                required_start_dt = datetime.strptime(required_start, '%Y-%m-%d')
                if data_start_dt > required_start_dt:
                    return False
            
            if required_end:
                required_end_dt = datetime.strptime(required_end, '%Y-%m-%d')
                if data_end_dt < required_end_dt:
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ—¶é—´èŒƒå›´æ—¶å‡ºé”™: {e}")
            return False
    
    def get_missing_data_report(self, stock_codes: List[str]) -> Dict[str, List[str]]:
        """
        ç”Ÿæˆç¼ºå¤±æ•°æ®æŠ¥å‘Š
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns:
            ç¼ºå¤±æ•°æ®æŠ¥å‘Š {ç±»å‹: [è‚¡ç¥¨ä»£ç åˆ—è¡¨]}
            
        Requirements: 1.2
        """
        validation_result = self.validate_tech_stock_data(stock_codes)
        
        report = {
            "missing_files": validation_result.missing_files,
            "insufficient_data": [item["code"] for item in validation_result.insufficient_data],
            "corrupted_files": validation_result.corrupted_files,
            "valid_stocks": []
        }
        
        # è®¡ç®—æœ‰æ•ˆè‚¡ç¥¨
        all_problem_codes = set(
            report["missing_files"] + 
            report["insufficient_data"] + 
            report["corrupted_files"]
        )
        
        report["valid_stocks"] = [
            code for code in stock_codes 
            if code not in all_problem_codes
        ]
        
        return report
    
    def get_tech_stock_pool_status(self) -> Dict[str, Any]:
        """
        è·å–æ•´ä¸ªç§‘æŠ€è‚¡æ± çš„æ•°æ®çŠ¶æ€æ¦‚è§ˆ
        
        Returns:
            ç§‘æŠ€è‚¡æ± æ•°æ®çŠ¶æ€æ¦‚è§ˆ
            
        Requirements: 3.1, 3.3
        """
        all_codes = self.tech_stock_pool.get_all_codes()
        validation_result = self.validate_tech_stock_data(all_codes)
        
        # æŒ‰è¡Œä¸šç»Ÿè®¡
        sector_stats = {}
        for sector in self.tech_stock_pool.get_sectors():
            sector_codes = self.tech_stock_pool.get_codes_by_sector(sector)
            sector_validation = self.validate_tech_stock_data(sector_codes)
            
            sector_stats[sector] = {
                "total": len(sector_codes),
                "valid": sector_validation.valid_stocks,
                "missing": len(sector_validation.missing_files),
                "insufficient": len(sector_validation.insufficient_data),
                "corrupted": len(sector_validation.corrupted_files)
            }
        
        return {
            "overall": {
                "total_stocks": validation_result.total_stocks,
                "valid_stocks": validation_result.valid_stocks,
                "missing_files": len(validation_result.missing_files),
                "insufficient_data": len(validation_result.insufficient_data),
                "corrupted_files": len(validation_result.corrupted_files),
                "completion_rate": validation_result.valid_stocks / validation_result.total_stocks if validation_result.total_stocks > 0 else 0
            },
            "by_sector": sector_stats,
            "problem_stocks": {
                "missing_files": validation_result.missing_files,
                "insufficient_data": validation_result.insufficient_data,
                "corrupted_files": validation_result.corrupted_files
            }
        }
    
    def _generate_error_message(
        self,
        missing_files: List[str],
        insufficient_data: List[Dict[str, str]],
        corrupted_files: List[str]
    ) -> Tuple[Optional[str], Optional[str]]:
        """
        ç”Ÿæˆé”™è¯¯ä¿¡æ¯å’Œè§£å†³æ–¹æ¡ˆæç¤º
        
        ä½¿ç”¨æ ‡å‡†åŒ–çš„é”™è¯¯ä¿¡æ¯æ¨¡æ¿ï¼Œæä¾›å‹å¥½çš„ä¸­æ–‡æç¤ºã€‚
        
        Args:
            missing_files: ç¼ºå¤±æ–‡ä»¶çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
            insufficient_data: æ•°æ®ä¸è¶³çš„è‚¡ç¥¨ä¿¡æ¯åˆ—è¡¨
            corrupted_files: æŸåæ–‡ä»¶çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns:
            (é”™è¯¯ä¿¡æ¯, è§£å†³æ–¹æ¡ˆæç¤º)
            
        Requirements: 1.2, 1.3, 5.1
        """
        if not missing_files and not insufficient_data and not corrupted_files:
            return None, None
        
        error_parts = []
        
        # ç¼ºå¤±æ•°æ®æ–‡ä»¶
        if missing_files:
            error_parts.append(f"ğŸ“ **{ErrorMessages.MISSING_DATA_FILE}** ({len(missing_files)} åª)")
            for code in missing_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                name = self.tech_stock_pool.get_stock_name(code)
                error_parts.append(f"   â€¢ {code} ({name})")
            if len(missing_files) > 5:
                error_parts.append(f"   â€¢ ... è¿˜æœ‰ {len(missing_files) - 5} åª")
        
        # æ•°æ®æ—¶é—´èŒƒå›´ä¸è¶³
        if insufficient_data:
            error_parts.append(f"ğŸ“… **{ErrorMessages.INSUFFICIENT_DATA}** ({len(insufficient_data)} åª)")
            for item in insufficient_data[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                error_parts.append(
                    f"   â€¢ {item['code']} ({item['name']}): "
                    f"{item['first_date']} ~ {item['last_date']}"
                )
            if len(insufficient_data) > 5:
                error_parts.append(f"   â€¢ ... è¿˜æœ‰ {len(insufficient_data) - 5} åª")
        
        # æ•°æ®æ–‡ä»¶æŸå
        if corrupted_files:
            error_parts.append(f"âš ï¸ **{ErrorMessages.CORRUPTED_DATA}** ({len(corrupted_files)} åª)")
            for code in corrupted_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                name = self.tech_stock_pool.get_stock_name(code)
                error_parts.append(f"   â€¢ {code} ({name})")
            if len(corrupted_files) > 5:
                error_parts.append(f"   â€¢ ... è¿˜æœ‰ {len(corrupted_files) - 5} åª")
        
        error_message = "ğŸ”¬ **ç§‘æŠ€è‚¡æ•°æ®éªŒè¯å¤±è´¥**\n\n" + "\n".join(error_parts)
        
        # ç”Ÿæˆè§£å†³æ–¹æ¡ˆæç¤º
        solution_hints = ErrorMessages.get_solution_hints(
            has_missing=len(missing_files) > 0,
            has_insufficient=len(insufficient_data) > 0,
            has_corrupted=len(corrupted_files) > 0
        )
        
        solution_hint = "ğŸ’¡ **å»ºè®®è§£å†³æ–¹æ¡ˆ**:\n" + "\n".join(f"â€¢ {hint}" for hint in solution_hints)
        
        return error_message, solution_hint
    
    def get_friendly_error_summary(self, validation_result: 'DataValidationResult') -> Dict[str, Any]:
        """
        è·å–å‹å¥½çš„é”™è¯¯æ‘˜è¦ä¿¡æ¯
        
        ç”¨äºUIæ˜¾ç¤ºï¼Œæä¾›ç»“æ„åŒ–çš„é”™è¯¯ä¿¡æ¯ã€‚
        
        Args:
            validation_result: æ•°æ®éªŒè¯ç»“æœ
        
        Returns:
            å‹å¥½çš„é”™è¯¯æ‘˜è¦å­—å…¸
            
        Requirements: 5.1
        """
        if validation_result.is_valid:
            return {
                'has_error': False,
                'title': 'âœ… æ•°æ®éªŒè¯é€šè¿‡',
                'summary': f'æ‰€æœ‰ {validation_result.total_stocks} åªç§‘æŠ€è‚¡æ•°æ®å®Œæ•´',
                'details': [],
                'solutions': []
            }
        
        # ç»Ÿè®¡é—®é¢˜æ•°é‡
        total_issues = (
            len(validation_result.missing_files) + 
            len(validation_result.insufficient_data) + 
            len(validation_result.corrupted_files)
        )
        
        details = []
        
        if validation_result.missing_files:
            details.append({
                'type': 'missing',
                'icon': 'ğŸ“',
                'title': ErrorMessages.MISSING_DATA_FILE,
                'count': len(validation_result.missing_files),
                'items': [
                    f"{code} ({self.tech_stock_pool.get_stock_name(code)})"
                    for code in validation_result.missing_files
                ]
            })
        
        if validation_result.insufficient_data:
            details.append({
                'type': 'insufficient',
                'icon': 'ğŸ“…',
                'title': ErrorMessages.INSUFFICIENT_DATA,
                'count': len(validation_result.insufficient_data),
                'items': [
                    f"{item['code']} ({item['name']}): {item['first_date']} ~ {item['last_date']}"
                    for item in validation_result.insufficient_data
                ]
            })
        
        if validation_result.corrupted_files:
            details.append({
                'type': 'corrupted',
                'icon': 'âš ï¸',
                'title': ErrorMessages.CORRUPTED_DATA,
                'count': len(validation_result.corrupted_files),
                'items': [
                    f"{code} ({self.tech_stock_pool.get_stock_name(code)})"
                    for code in validation_result.corrupted_files
                ]
            })
        
        solutions = ErrorMessages.get_solution_hints(
            has_missing=len(validation_result.missing_files) > 0,
            has_insufficient=len(validation_result.insufficient_data) > 0,
            has_corrupted=len(validation_result.corrupted_files) > 0
        )
        
        return {
            'has_error': True,
            'title': f'âŒ æ•°æ®éªŒè¯å¤±è´¥ ({total_issues} ä¸ªé—®é¢˜)',
            'summary': f'{validation_result.valid_stocks}/{validation_result.total_stocks} åªè‚¡ç¥¨æ•°æ®æœ‰æ•ˆ',
            'details': details,
            'solutions': solutions
        }