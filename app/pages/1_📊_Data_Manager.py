"""
MiniQuant-Lite æ•°æ®ç®¡ç†é¡µé¢

æä¾›æ•°æ®ç®¡ç†åŠŸèƒ½ï¼š
- æ•°æ®çŠ¶æ€æ¦‚è§ˆ
- è‚¡ç¥¨æ•°æ®ä¸‹è½½
- ç§‘æŠ€è‚¡æ•°æ®ä¸“åŒº
- ä¸€é”®æ¸…ç©ºç¼“å­˜

Requirements: 7.2, 7.3, 5.1, 5.2, 5.3
"""

import streamlit as st
import sys
import os
from datetime import date, timedelta
from typing import List, Dict, Any
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from config.settings import get_settings
from config.stock_pool import get_watchlist, StockPool, validate_stock_codes
from core.data_feed import DataFeed
from core.tech_stock.data_validator import TechDataValidator
from core.tech_stock.data_downloader import TechDataDownloader
from config.tech_stock_pool import get_tech_stock_pool, get_all_tech_stocks


def get_data_feed() -> DataFeed:
    """è·å– DataFeed å®ä¾‹"""
    settings = get_settings()
    return DataFeed(
        raw_path=settings.path.get_raw_path(),
        processed_path=settings.path.get_processed_path()
    )


def render_data_status(data_feed: DataFeed, stock_pool: List[str]):
    """
    æ¸²æŸ“æ•°æ®çŠ¶æ€æ¦‚è§ˆ
    
    Args:
        data_feed: DataFeed å®ä¾‹
        stock_pool: è‚¡ç¥¨æ± åˆ—è¡¨
    """
    st.subheader("ğŸ“Š æ•°æ®çŠ¶æ€æ¦‚è§ˆ")
    
    if not stock_pool:
        st.warning("è‚¡ç¥¨æ± ä¸ºç©ºï¼Œè¯·å…ˆé…ç½®è‚¡ç¥¨æ± ")
        return
    
    # è·å–æ•°æ®çŠ¶æ€
    status = data_feed.get_data_status(stock_pool)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total = len(stock_pool)
    downloaded = sum(1 for s in status.values() if s['exists'])
    missing = total - downloaded
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("è‚¡ç¥¨æ± æ€»æ•°", f"{total} åª")
    with col2:
        st.metric("å·²ä¸‹è½½", f"{downloaded} åª", delta=None if downloaded == total else f"-{missing}")
    with col3:
        st.metric("å¾…ä¸‹è½½", f"{missing} åª")
    
    # æ•°æ®çŠ¶æ€è¡¨æ ¼
    if status:
        st.markdown("#### è¯¦ç»†çŠ¶æ€")
        
        # è½¬æ¢ä¸º DataFrame
        data = []
        for code, info in status.items():
            data.append({
                'è‚¡ç¥¨ä»£ç ': code,
                'çŠ¶æ€': 'âœ… å·²ä¸‹è½½' if info['exists'] else 'âŒ æœªä¸‹è½½',
                'æœ€åæ›´æ–°': info['last_date'] if info['last_date'] else '-',
                'è®°å½•æ•°': info['record_count'] if info['record_count'] else 0
            })
        
        df = pd.DataFrame(data)
        
        # ä½¿ç”¨ dataframe æ˜¾ç¤ºï¼Œæ”¯æŒæ’åº
        st.dataframe(
            df,
            use_container_width=True,
            hide_index=True,
            column_config={
                'è‚¡ç¥¨ä»£ç ': st.column_config.TextColumn('è‚¡ç¥¨ä»£ç ', width='small'),
                'çŠ¶æ€': st.column_config.TextColumn('çŠ¶æ€', width='small'),
                'æœ€åæ›´æ–°': st.column_config.TextColumn('æœ€åæ›´æ–°', width='medium'),
                'è®°å½•æ•°': st.column_config.NumberColumn('è®°å½•æ•°', width='small')
            }
        )


def render_download_section(data_feed: DataFeed, stock_pool: List[str]):
    """
    æ¸²æŸ“æ•°æ®ä¸‹è½½åŒºåŸŸ
    
    Args:
        data_feed: DataFeed å®ä¾‹
        stock_pool: è‚¡ç¥¨æ± åˆ—è¡¨
    """
    st.subheader("ğŸ“¥ æ•°æ®ä¸‹è½½")
    
    settings = get_settings()
    
    # ä¸‹è½½å‚æ•°é…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        # æ—¥æœŸèŒƒå›´
        default_end = date.today()
        default_start = default_end - timedelta(days=365)
        
        start_date = st.date_input(
            "å¼€å§‹æ—¥æœŸ",
            value=default_start,
            help="æ•°æ®ä¸‹è½½çš„å¼€å§‹æ—¥æœŸ"
        )
    
    with col2:
        end_date = st.date_input(
            "ç»“æŸæ—¥æœŸ",
            value=default_end,
            help="æ•°æ®ä¸‹è½½çš„ç»“æŸæ—¥æœŸ"
        )
    
    # ä¸‹è½½é€‰é¡¹
    st.markdown("#### ä¸‹è½½é€‰é¡¹")
    
    col1, col2 = st.columns(2)
    
    with col1:
        download_all = st.checkbox(
            "ä¸‹è½½å…¨éƒ¨è‚¡ç¥¨æ± ",
            value=True,
            help="å‹¾é€‰åä¸‹è½½è‚¡ç¥¨æ± ä¸­æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ®"
        )
    
    with col2:
        overwrite = st.checkbox(
            "è¦†ç›–å·²æœ‰æ•°æ®",
            value=True,
            help="å‹¾é€‰åä¼šè¦†ç›–å·²ä¸‹è½½çš„æ•°æ®ï¼ˆæ¨èï¼Œç¡®ä¿å¤æƒæ•°æ®å‡†ç¡®ï¼‰"
        )
    
    # å•åªè‚¡ç¥¨ä¸‹è½½
    if not download_all:
        selected_codes = st.multiselect(
            "é€‰æ‹©è¦ä¸‹è½½çš„è‚¡ç¥¨",
            options=stock_pool,
            default=[],
            help="é€‰æ‹©éœ€è¦ä¸‹è½½æ•°æ®çš„è‚¡ç¥¨"
        )
    else:
        selected_codes = stock_pool
    
    # ä¸‹è½½æŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹ä¸‹è½½", type="primary", disabled=not selected_codes):
        if not selected_codes:
            st.warning("è¯·é€‰æ‹©è¦ä¸‹è½½çš„è‚¡ç¥¨")
            return
        
        start_str = start_date.strftime('%Y-%m-%d')
        end_str = end_date.strftime('%Y-%m-%d')
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        success_count = 0
        fail_count = 0
        total = len(selected_codes)
        
        for i, code in enumerate(selected_codes):
            status_text.text(f"æ­£åœ¨ä¸‹è½½: {code} ({i+1}/{total})")
            
            try:
                # ä¸‹è½½æ•°æ®
                df = data_feed.download_stock_data(
                    code=code,
                    start_date=start_str,
                    end_date=end_str,
                    adjust='qfq'
                )
                
                if df is not None and not df.empty:
                    # æ¸…æ´—å¹¶ä¿å­˜æ•°æ®
                    cleaned = data_feed.clean_data(df)
                    if not cleaned.empty:
                        file_path = os.path.join(
                            settings.path.get_processed_path(),
                            f"{code}.csv"
                        )
                        cleaned.to_csv(file_path, index=False)
                        success_count += 1
                    else:
                        fail_count += 1
                else:
                    fail_count += 1
                    
            except Exception as e:
                fail_count += 1
                st.error(f"ä¸‹è½½ {code} å¤±è´¥: {str(e)}")
            
            progress_bar.progress((i + 1) / total)
        
        status_text.empty()
        progress_bar.empty()
        
        if success_count > 0:
            st.success(f"âœ… ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {success_count} åªï¼Œå¤±è´¥: {fail_count} åª")
        else:
            st.error(f"âŒ ä¸‹è½½å¤±è´¥ï¼è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– AkShare ç‰ˆæœ¬")
        
        # åˆ·æ–°é¡µé¢
        st.rerun()


def render_cache_management(data_feed: DataFeed):
    """
    æ¸²æŸ“ç¼“å­˜ç®¡ç†åŒºåŸŸ
    
    Args:
        data_feed: DataFeed å®ä¾‹
    """
    st.subheader("ğŸ—‘ï¸ ç¼“å­˜ç®¡ç†")
    
    # ========== å†…å­˜ç¼“å­˜çŠ¶æ€ ==========
    st.markdown("#### ğŸ’¾ å†…å­˜ç¼“å­˜")
    
    cache_stats = data_feed.get_cache_stats()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("è‚¡ç¥¨æ•°æ®ç¼“å­˜", f"{cache_stats['stock_data_count']} åª")
    with col2:
        snapshot_status = "âœ… å·²ç¼“å­˜" if cache_stats['has_market_snapshot'] else "âŒ æœªç¼“å­˜"
        st.metric("å¸‚åœºå¿«ç…§", snapshot_status)
    with col3:
        names_status = "âœ… å·²ç¼“å­˜" if cache_stats['has_stock_names'] else "âŒ æœªç¼“å­˜"
        st.metric("è‚¡ç¥¨åç§°", names_status)
    
    st.caption("ğŸ’¡ å†…å­˜ç¼“å­˜å¯åŠ é€Ÿé‡å¤æ•°æ®è®¿é—®ï¼ŒTTL: è‚¡ç¥¨æ•°æ® 5åˆ†é’Ÿ / å¸‚åœºå¿«ç…§ 1åˆ†é’Ÿ / è‚¡ç¥¨åç§° 1å°æ—¶")
    
    # æ¸…ç©ºå†…å­˜ç¼“å­˜æŒ‰é’®
    if st.button("ğŸ§¹ æ¸…ç©ºå†…å­˜ç¼“å­˜", help="ä»…æ¸…ç©ºå†…å­˜ç¼“å­˜ï¼Œä¸å½±å“å·²ä¸‹è½½çš„æ–‡ä»¶"):
        data_feed.clear_memory_cache()
        st.success("âœ… å†…å­˜ç¼“å­˜å·²æ¸…ç©º")
        st.rerun()
    
    st.divider()
    
    # ========== æ–‡ä»¶ç¼“å­˜çŠ¶æ€ ==========
    st.markdown("#### ğŸ“ æ–‡ä»¶ç¼“å­˜")
    
    st.warning("""
    **æ³¨æ„**ï¼šæ¸…ç©ºæ–‡ä»¶ç¼“å­˜å°†åˆ é™¤æ‰€æœ‰å·²ä¸‹è½½çš„è‚¡ç¥¨æ•°æ®ï¼Œéœ€è¦é‡æ–°ä¸‹è½½ã€‚
    
    é€‚ç”¨åœºæ™¯ï¼š
    - æ•°æ®å‡ºç°å¼‚å¸¸æˆ–æŸå
    - éœ€è¦å®Œå…¨é‡æ–°ä¸‹è½½æ•°æ®
    - ç£ç›˜ç©ºé—´ä¸è¶³
    """)
    
    # æ˜¾ç¤ºç¼“å­˜å¤§å°
    settings = get_settings()
    raw_path = settings.path.get_raw_path()
    processed_path = settings.path.get_processed_path()
    
    def get_dir_size(path: str) -> int:
        """è·å–ç›®å½•å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        total = 0
        if os.path.exists(path):
            for file in os.listdir(path):
                file_path = os.path.join(path, file)
                if os.path.isfile(file_path):
                    total += os.path.getsize(file_path)
        return total
    
    raw_size = get_dir_size(raw_path)
    processed_size = get_dir_size(processed_path)
    total_size = raw_size + processed_size
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("åŸå§‹æ•°æ®", f"{raw_size / 1024 / 1024:.2f} MB")
    with col2:
        st.metric("å¤„ç†åæ•°æ®", f"{processed_size / 1024 / 1024:.2f} MB")
    with col3:
        st.metric("æ€»è®¡", f"{total_size / 1024 / 1024:.2f} MB")
    
    # ä¸€é”®æ¸…ç©ºç¼“å­˜æŒ‰é’®
    col1, col2 = st.columns([1, 3])
    with col1:
        if st.button("ğŸ—‘ï¸ ä¸€é”®æ¸…ç©ºç¼“å­˜", type="secondary"):
            st.session_state['confirm_clear'] = True
    
    # ç¡®è®¤å¯¹è¯æ¡†
    if st.session_state.get('confirm_clear', False):
        st.error("âš ï¸ ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰ç¼“å­˜æ•°æ®å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ¢å¤ï¼")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ç¡®è®¤æ¸…ç©º", type="primary"):
                success = data_feed.clear_cache()
                if success:
                    st.success("âœ… ç¼“å­˜å·²æ¸…ç©ºï¼")
                else:
                    st.error("âŒ æ¸…ç©ºç¼“å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™")
                st.session_state['confirm_clear'] = False
                st.rerun()
        with col2:
            if st.button("âŒ å–æ¶ˆ"):
                st.session_state['confirm_clear'] = False
                st.rerun()


def render_tech_stock_data_section(data_feed: DataFeed):
    """
    æ¸²æŸ“ç§‘æŠ€è‚¡æ•°æ®ä¸“åŒº
    
    æ˜¾ç¤ºç§‘æŠ€è‚¡æ± ä¸­æ‰€æœ‰è‚¡ç¥¨çš„æ•°æ®çŠ¶æ€ï¼Œæä¾›æ‰¹é‡ä¸‹è½½å’Œæ›´æ–°åŠŸèƒ½ã€‚
    
    Args:
        data_feed: DataFeed å®ä¾‹
        
    Requirements: 5.1, 5.2, 5.3
    """
    st.subheader("ğŸ”¬ ç§‘æŠ€è‚¡æ•°æ®ä¸“åŒº")
    
    # åˆå§‹åŒ–éªŒè¯å™¨å’Œä¸‹è½½å™¨
    validator = TechDataValidator(data_feed)
    downloader = TechDataDownloader(data_feed)
    tech_pool = get_tech_stock_pool()
    
    # è·å–ç§‘æŠ€è‚¡æ± çŠ¶æ€æ¦‚è§ˆ
    try:
        pool_status = validator.get_tech_stock_pool_status()
    except Exception as e:
        st.error(f"è·å–ç§‘æŠ€è‚¡æ•°æ®çŠ¶æ€å¤±è´¥: {e}")
        return
    
    overall = pool_status['overall']
    
    # ========== æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡ ==========
    st.markdown("#### ğŸ“ˆ æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç§‘æŠ€è‚¡æ€»æ•°", f"{overall['total_stocks']} åª")
    with col2:
        completion_pct = overall['completion_rate'] * 100
        delta_color = "normal" if completion_pct >= 80 else "inverse"
        st.metric(
            "æ•°æ®å®Œæ•´ç‡", 
            f"{completion_pct:.1f}%",
            delta=f"{overall['valid_stocks']} åªæœ‰æ•ˆ" if overall['valid_stocks'] > 0 else None
        )
    with col3:
        missing_count = overall['missing_files']
        st.metric(
            "ç¼ºå¤±æ•°æ®", 
            f"{missing_count} åª",
            delta=f"-{missing_count}" if missing_count > 0 else None,
            delta_color="inverse" if missing_count > 0 else "off"
        )
    with col4:
        problem_count = overall['insufficient_data'] + overall['corrupted_files']
        st.metric(
            "é—®é¢˜æ•°æ®", 
            f"{problem_count} åª",
            delta=f"-{problem_count}" if problem_count > 0 else None,
            delta_color="inverse" if problem_count > 0 else "off"
        )
    
    # ========== æŒ‰è¡Œä¸šç»Ÿè®¡ ==========
    st.markdown("#### ğŸ­ æŒ‰è¡Œä¸šç»Ÿè®¡")
    
    sector_data = []
    for sector, stats in pool_status['by_sector'].items():
        completion_rate = stats['valid'] / stats['total'] * 100 if stats['total'] > 0 else 0
        status_icon = "âœ…" if completion_rate == 100 else ("âš ï¸" if completion_rate >= 50 else "âŒ")
        sector_data.append({
            'è¡Œä¸š': sector,
            'çŠ¶æ€': status_icon,
            'æ€»æ•°': stats['total'],
            'æœ‰æ•ˆ': stats['valid'],
            'ç¼ºå¤±': stats['missing'],
            'ä¸è¶³': stats['insufficient'],
            'æŸå': stats['corrupted'],
            'å®Œæ•´ç‡': f"{completion_rate:.0f}%"
        })
    
    sector_df = pd.DataFrame(sector_data)
    st.dataframe(
        sector_df,
        use_container_width=True,
        hide_index=True,
        column_config={
            'è¡Œä¸š': st.column_config.TextColumn('è¡Œä¸š', width='medium'),
            'çŠ¶æ€': st.column_config.TextColumn('çŠ¶æ€', width='small'),
            'æ€»æ•°': st.column_config.NumberColumn('æ€»æ•°', width='small'),
            'æœ‰æ•ˆ': st.column_config.NumberColumn('æœ‰æ•ˆ', width='small'),
            'ç¼ºå¤±': st.column_config.NumberColumn('ç¼ºå¤±', width='small'),
            'ä¸è¶³': st.column_config.NumberColumn('ä¸è¶³', width='small'),
            'æŸå': st.column_config.NumberColumn('æŸå', width='small'),
            'å®Œæ•´ç‡': st.column_config.TextColumn('å®Œæ•´ç‡', width='small')
        }
    )
    
    # ========== é—®é¢˜è‚¡ç¥¨è¯¦æƒ… ==========
    problem_stocks = pool_status['problem_stocks']
    has_problems = (
        len(problem_stocks['missing_files']) > 0 or 
        len(problem_stocks['insufficient_data']) > 0 or 
        len(problem_stocks['corrupted_files']) > 0
    )
    
    if has_problems:
        with st.expander("âš ï¸ æŸ¥çœ‹é—®é¢˜è‚¡ç¥¨è¯¦æƒ…", expanded=False):
            if problem_stocks['missing_files']:
                st.markdown("**ç¼ºå¤±æ•°æ®æ–‡ä»¶çš„è‚¡ç¥¨:**")
                missing_names = [
                    f"{code} ({tech_pool.get_stock_name(code)})" 
                    for code in problem_stocks['missing_files']
                ]
                st.text(", ".join(missing_names))
            
            if problem_stocks['insufficient_data']:
                st.markdown("**æ•°æ®æ—¶é—´èŒƒå›´ä¸è¶³çš„è‚¡ç¥¨:**")
                for item in problem_stocks['insufficient_data']:
                    st.text(f"â€¢ {item['code']} ({item['name']}): {item['first_date']} ~ {item['last_date']}")
            
            if problem_stocks['corrupted_files']:
                st.markdown("**æ•°æ®æ–‡ä»¶æŸåçš„è‚¡ç¥¨:**")
                corrupted_names = [
                    f"{code} ({tech_pool.get_stock_name(code)})" 
                    for code in problem_stocks['corrupted_files']
                ]
                st.text(", ".join(corrupted_names))
    
    # ========== æ‰¹é‡ä¸‹è½½åŠŸèƒ½ ==========
    st.markdown("#### ğŸ“¥ æ‰¹é‡ä¸‹è½½")
    
    col1, col2 = st.columns(2)
    
    with col1:
        download_option = st.radio(
            "ä¸‹è½½é€‰é¡¹",
            options=["ä»…ä¸‹è½½ç¼ºå¤±æ•°æ®", "æ›´æ–°å…¨éƒ¨ç§‘æŠ€è‚¡æ•°æ®"],
            index=0,
            help="é€‰æ‹©ä¸‹è½½æ¨¡å¼"
        )
    
    with col2:
        force_update = st.checkbox(
            "å¼ºåˆ¶è¦†ç›–å·²æœ‰æ•°æ®",
            value=False,
            help="å‹¾é€‰åä¼šé‡æ–°ä¸‹è½½æ‰€æœ‰æ•°æ®ï¼ŒåŒ…æ‹¬å·²å­˜åœ¨çš„"
        )
    
    # ä¸‹è½½æŒ‰é’®
    download_key = 'tech_stock_download_in_progress'
    
    if st.button("ğŸš€ å¼€å§‹ä¸‹è½½ç§‘æŠ€è‚¡æ•°æ®", type="primary", disabled=st.session_state.get(download_key, False)):
        st.session_state[download_key] = True
        
        # ç¡®å®šè¦ä¸‹è½½çš„è‚¡ç¥¨åˆ—è¡¨
        if download_option == "ä»…ä¸‹è½½ç¼ºå¤±æ•°æ®":
            codes_to_download = problem_stocks['missing_files'] + problem_stocks['corrupted_files']
            # æ·»åŠ æ•°æ®ä¸è¶³çš„è‚¡ç¥¨
            codes_to_download += [item['code'] for item in problem_stocks['insufficient_data']]
            codes_to_download = list(set(codes_to_download))  # å»é‡
        else:
            codes_to_download = get_all_tech_stocks()
        
        if not codes_to_download:
            st.info("âœ… æ‰€æœ‰ç§‘æŠ€è‚¡æ•°æ®å·²å®Œæ•´ï¼Œæ— éœ€ä¸‹è½½")
            st.session_state[download_key] = False
        else:
            st.info(f"å‡†å¤‡ä¸‹è½½ {len(codes_to_download)} åªç§‘æŠ€è‚¡æ•°æ®...")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # æ‰§è¡Œä¸‹è½½
            def update_progress(progress):
                pct = progress.completed_stocks / progress.total_stocks if progress.total_stocks > 0 else 0
                progress_bar.progress(pct)
                status_text.text(
                    f"æ­£åœ¨ä¸‹è½½: {progress.current_stock} ({progress.current_stock_name}) "
                    f"[{progress.completed_stocks}/{progress.total_stocks}] "
                    f"æˆåŠŸ: {progress.success_count}, å¤±è´¥: {progress.failed_count}"
                )
            
            result = downloader.download_stocks(
                stock_codes=codes_to_download,
                progress_callback=update_progress,
                force_update=force_update or download_option == "æ›´æ–°å…¨éƒ¨ç§‘æŠ€è‚¡æ•°æ®"
            )
            
            progress_bar.empty()
            status_text.empty()
            
            # æ˜¾ç¤ºç»“æœ
            if result.success:
                st.success(f"âœ… ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {len(result.successful_downloads)} åªï¼Œè·³è¿‡: {len(result.skipped_downloads)} åª")
            else:
                st.warning(
                    f"âš ï¸ ä¸‹è½½å®Œæˆï¼Œéƒ¨åˆ†å¤±è´¥ã€‚æˆåŠŸ: {len(result.successful_downloads)} åªï¼Œ"
                    f"å¤±è´¥: {len(result.failed_downloads)} åªï¼Œè·³è¿‡: {len(result.skipped_downloads)} åª"
                )
                
                if result.failed_downloads:
                    with st.expander("æŸ¥çœ‹å¤±è´¥è¯¦æƒ…"):
                        for failed in result.failed_downloads:
                            st.text(f"â€¢ {failed['code']} ({failed['name']}): {failed.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            st.session_state[download_key] = False
            st.rerun()
    
    # ========== æ•°æ®è¦†ç›–èŒƒå›´ ==========
    st.markdown("#### ğŸ“… æ•°æ®è¦†ç›–èŒƒå›´")
    
    # è·å–æ•°æ®æ—¶é—´èŒƒå›´ç»Ÿè®¡
    all_codes = get_all_tech_stocks()
    date_ranges = []
    
    for code in all_codes[:10]:  # åªæ£€æŸ¥å‰10åªä»¥æé«˜æ€§èƒ½
        status = validator.check_single_stock_data(code)
        if status.has_file and status.first_date and status.last_date:
            date_ranges.append({
                'first': status.first_date,
                'last': status.last_date
            })
    
    if date_ranges:
        earliest = min(d['first'] for d in date_ranges)
        latest = max(d['last'] for d in date_ranges)
        st.info(f"ğŸ“Š æ•°æ®è¦†ç›–èŒƒå›´ï¼ˆé‡‡æ ·ï¼‰: {earliest} ~ {latest}")
    else:
        st.warning("âš ï¸ æš‚æ— å¯ç”¨æ•°æ®ï¼Œè¯·å…ˆä¸‹è½½ç§‘æŠ€è‚¡æ•°æ®")


def render_stock_pool_management():
    """æ¸²æŸ“è‚¡ç¥¨æ± ç®¡ç†åŒºåŸŸ"""
    st.subheader("ğŸ“‹ è‚¡ç¥¨æ± ç®¡ç†")
    
    # å½“å‰è‚¡ç¥¨æ± 
    current_pool = get_watchlist()
    
    st.markdown(f"**å½“å‰è‚¡ç¥¨æ± **: {len(current_pool)} åªè‚¡ç¥¨")
    
    # æ˜¾ç¤ºå½“å‰è‚¡ç¥¨æ± 
    with st.expander("æŸ¥çœ‹å½“å‰è‚¡ç¥¨æ± ", expanded=False):
        if current_pool:
            # æ¯è¡Œæ˜¾ç¤º 6 ä¸ªè‚¡ç¥¨ä»£ç 
            cols = st.columns(6)
            for i, code in enumerate(current_pool):
                cols[i % 6].code(code)
        else:
            st.info("è‚¡ç¥¨æ± ä¸ºç©º")
    
    # æ·»åŠ è‚¡ç¥¨
    st.markdown("#### æ·»åŠ è‚¡ç¥¨")
    new_codes = st.text_input(
        "è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆå¤šä¸ªä»£ç ç”¨é€—å·åˆ†éš”ï¼‰",
        placeholder="ä¾‹å¦‚: 000001, 600036, 300750",
        help="è¾“å…¥è¦æ·»åŠ åˆ°è‚¡ç¥¨æ± çš„è‚¡ç¥¨ä»£ç "
    )
    
    if st.button("â• æ·»åŠ åˆ°è‚¡ç¥¨æ± "):
        if new_codes:
            codes = [c.strip() for c in new_codes.split(',') if c.strip()]
            valid_codes = validate_stock_codes(codes)
            
            if valid_codes:
                added = 0
                for code in valid_codes:
                    if code not in current_pool:
                        StockPool.add_code(code)
                        added += 1
                
                if added > 0:
                    st.success(f"âœ… æˆåŠŸæ·»åŠ  {added} åªè‚¡ç¥¨")
                    st.rerun()
                else:
                    st.info("æ‰€æœ‰è‚¡ç¥¨å·²åœ¨è‚¡ç¥¨æ± ä¸­")
            else:
                st.error("è¾“å…¥çš„è‚¡ç¥¨ä»£ç æ ¼å¼æ— æ•ˆ")
        else:
            st.warning("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ")


def main():
    """æ•°æ®ç®¡ç†é¡µé¢ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="æ•°æ®ç®¡ç† - MiniQuant-Lite",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    st.title("ğŸ“Š æ•°æ®ç®¡ç†")
    st.markdown("ç®¡ç†è‚¡ç¥¨æ•°æ®çš„ä¸‹è½½ã€æ›´æ–°å’Œç¼“å­˜")
    
    st.divider()
    
    # åˆå§‹åŒ–
    data_feed = get_data_feed()
    stock_pool = get_watchlist()
    
    # æ•°æ®çŠ¶æ€æ¦‚è§ˆ
    render_data_status(data_feed, stock_pool)
    
    st.divider()
    
    # æ•°æ®ä¸‹è½½
    render_download_section(data_feed, stock_pool)
    
    st.divider()
    
    # ç§‘æŠ€è‚¡æ•°æ®ä¸“åŒº (Task 3.1)
    render_tech_stock_data_section(data_feed)
    
    st.divider()
    
    # è‚¡ç¥¨æ± ç®¡ç†
    render_stock_pool_management()
    
    st.divider()
    
    # ç¼“å­˜ç®¡ç†
    render_cache_management(data_feed)


if __name__ == "__main__":
    main()
